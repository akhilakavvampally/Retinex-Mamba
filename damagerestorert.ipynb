{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import math\n",
        "import argparse\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "from skimage.metrics import structural_similarity as compare_ssim, peak_signal_noise_ratio as compare_psnr\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# ------------------- Model Components -------------------\n",
        "class DamageRestorer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Sequential(\n",
        "            nn.Conv2d(3, 3, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(3, 3, 3, padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 3, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_attn = x * self.attn(x)\n",
        "        return x + self.ffn(x_attn)\n",
        "\n",
        "class IlluminationEstimator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 1, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "class RetinexMamba(nn.Module):\n",
        "    def __init__(self, boost=0.7):\n",
        "        super().__init__()\n",
        "        self.ie = IlluminationEstimator()\n",
        "        self.restorer = DamageRestorer()\n",
        "        self.boost = boost\n",
        "\n",
        "    def forward(self, x):\n",
        "        illum_map = self.ie(x)\n",
        "        illum_map_boosted = torch.clamp(illum_map + self.boost, 0, 1.2)\n",
        "        illuminated = x * illum_map_boosted\n",
        "        enhanced = self.restorer(illuminated)\n",
        "        return torch.clamp(enhanced, 0, 1)\n",
        "\n",
        "# ------------------- Dataset -------------------\n",
        "class ImagePairDataset(Dataset):\n",
        "    def __init__(self, input_dir, target_dir, size=(256, 256)):\n",
        "        self.input_paths = sorted([os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
        "        self.target_paths = sorted([os.path.join(target_dir, f) for f in os.listdir(target_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
        "        self.size = size\n",
        "        self.transform = T.Compose([\n",
        "            T.Resize(size),\n",
        "            T.ToTensor()\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        inp_img = Image.open(self.input_paths[idx]).convert(\"RGB\")\n",
        "        tgt_img = Image.open(self.target_paths[idx]).convert(\"RGB\")\n",
        "        return self.transform(inp_img), self.transform(tgt_img), self.input_paths[idx]\n",
        "\n",
        "# ------------------- Loss Functions -------------------\n",
        "def ssim_loss(pred, target):\n",
        "    pred = pred.detach().cpu()\n",
        "    target = target.detach().cpu()\n",
        "    loss = 0\n",
        "    for i in range(pred.shape[0]):\n",
        "        pred_np = pred[i].permute(1, 2, 0).numpy()\n",
        "        target_np = target[i].permute(1, 2, 0).numpy()\n",
        "        ssim = compare_ssim(pred_np, target_np, channel_axis=2, data_range=1.0)\n",
        "        loss += 1 - ssim\n",
        "    return loss / pred.shape[0]\n",
        "\n",
        "# ------------------- Training -------------------\n",
        "def train(model, loader, optimizer, criterion, device, writer, epoch):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for i, (input_img, target_img, _) in enumerate(tqdm(loader, desc=\"Training\")):\n",
        "        input_img = input_img.to(device)\n",
        "        target_img = target_img.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(input_img)\n",
        "        loss = criterion(output, target_img) + 0.1 * ssim_loss(output, target_img)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        writer.add_scalar(\"Loss/Batch\", loss.item(), epoch * len(loader) + i)\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    writer.add_scalar(\"Loss/Epoch\", avg_loss, epoch)\n",
        "    return avg_loss\n",
        "\n",
        "# ------------------- Evaluation -------------------\n",
        "def evaluate(model, loader, device, writer, epoch, output_dir):\n",
        "    model.eval()\n",
        "    total_psnr, total_ssim = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for idx, (input_img, target_img, img_path) in enumerate(tqdm(loader, desc=\"Evaluating\")):\n",
        "            input_img = input_img.to(device)\n",
        "            target_img = target_img.to(device)\n",
        "            output = model(input_img)\n",
        "\n",
        "            # Use the first image in batch (batch size is 1 for val)\n",
        "            inp_np = input_img[0].permute(1, 2, 0).cpu().numpy()\n",
        "            out_np = output[0].permute(1, 2, 0).cpu().numpy()\n",
        "            tgt_np = target_img[0].permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "            psnr = compare_psnr(tgt_np, out_np, data_range=1.0)\n",
        "            ssim = compare_ssim(tgt_np, out_np, channel_axis=2, data_range=1.0)\n",
        "            total_psnr += psnr\n",
        "            total_ssim += ssim\n",
        "\n",
        "            if idx < 10:\n",
        "                concat_img = np.hstack((\n",
        "                    (inp_np * 255).astype(np.uint8),\n",
        "                    (out_np * 255).astype(np.uint8),\n",
        "                    (tgt_np * 255).astype(np.uint8)\n",
        "                ))\n",
        "                img_name = os.path.basename(img_path[0])\n",
        "                os.makedirs(output_dir, exist_ok=True)\n",
        "                cv2.imwrite(os.path.join(output_dir, f\"compare_epoch{epoch}_{img_name}\"), cv2.cvtColor(concat_img, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "    avg_psnr = total_psnr / len(loader)\n",
        "    avg_ssim = total_ssim / len(loader)\n",
        "    writer.add_scalar(\"Val/PSNR\", avg_psnr, epoch)\n",
        "    writer.add_scalar(\"Val/SSIM\", avg_ssim, epoch)\n",
        "    return avg_psnr, avg_ssim\n",
        "\n",
        "# ------------------- Main -------------------\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--input_dir', default='/content/drive/MyDrive/data/LOLv2/Real_captured/Test/Low')\n",
        "    parser.add_argument('--target_dir', default='/content/drive/MyDrive/data/LOLv2/Real_captured/Test/Normal')\n",
        "    parser.add_argument('--epochs', type=int, default=20)\n",
        "    parser.add_argument('--batch_size', type=int, default=4)\n",
        "    parser.add_argument('--lr', type=float, default=1e-4)\n",
        "    parser.add_argument('--save_path', default='/content/retinexmamba_trained.pth')\n",
        "    parser.add_argument('--log_dir', default='/content/runs')\n",
        "    parser.add_argument('--output_vis_dir', default='/content/validation_outputs')\n",
        "    args = parser.parse_args([])  # Allows Colab use\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model = RetinexMamba().to(device)\n",
        "\n",
        "    dataset = ImagePairDataset(args.input_dir, args.target_dir)\n",
        "    train_size = int(0.9 * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    train_ds, val_ds = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=1, shuffle=False)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
        "    criterion = nn.MSELoss()\n",
        "    writer = SummaryWriter(args.log_dir)\n",
        "\n",
        "    for epoch in range(args.epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{args.epochs}\")\n",
        "        train_loss = train(model, train_loader, optimizer, criterion, device, writer, epoch)\n",
        "        val_psnr, val_ssim = evaluate(model, val_loader, device, writer, epoch, args.output_vis_dir)\n",
        "        print(f\"Loss: {train_loss:.4f} | Val PSNR: {val_psnr:.2f}, SSIM: {val_ssim:.4f}\")\n",
        "\n",
        "    torch.save(model.state_dict(), args.save_path)\n",
        "    print(f\"\\n✅ Model saved to {args.save_path}\")\n",
        "    writer.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06UyeQ_sTYoU",
        "outputId": "72a4f4d3-cb1e-4337-e957-700a11df7fdc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 23/23 [00:26<00:00,  1.14s/it]\n",
            "Evaluating: 100%|██████████| 10/10 [00:02<00:00,  3.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0904 | Val PSNR: 14.18, SSIM: 0.5922\n",
            "\n",
            "Epoch 2/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 23/23 [00:07<00:00,  2.99it/s]\n",
            "Evaluating: 100%|██████████| 10/10 [00:00<00:00, 10.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0857 | Val PSNR: 14.48, SSIM: 0.6069\n",
            "\n",
            "Epoch 3/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 23/23 [00:08<00:00,  2.76it/s]\n",
            "Evaluating: 100%|██████████| 10/10 [00:00<00:00, 14.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0819 | Val PSNR: 14.76, SSIM: 0.6201\n",
            "\n",
            "Epoch 4/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 23/23 [00:08<00:00,  2.66it/s]\n",
            "Evaluating: 100%|██████████| 10/10 [00:00<00:00, 13.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0789 | Val PSNR: 15.03, SSIM: 0.6319\n",
            "\n",
            "Epoch 5/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 23/23 [00:07<00:00,  3.05it/s]\n",
            "Evaluating: 100%|██████████| 10/10 [00:00<00:00, 13.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0745 | Val PSNR: 15.28, SSIM: 0.6422\n",
            "\n",
            "Epoch 6/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 23/23 [00:08<00:00,  2.64it/s]\n",
            "Evaluating: 100%|██████████| 10/10 [00:00<00:00, 13.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0730 | Val PSNR: 15.51, SSIM: 0.6511\n",
            "\n",
            "Epoch 7/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 23/23 [00:07<00:00,  2.89it/s]\n",
            "Evaluating: 100%|██████████| 10/10 [00:00<00:00, 10.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0697 | Val PSNR: 15.72, SSIM: 0.6591\n",
            "\n",
            "Epoch 8/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 23/23 [00:07<00:00,  2.89it/s]\n",
            "Evaluating: 100%|██████████| 10/10 [00:00<00:00, 13.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0674 | Val PSNR: 15.91, SSIM: 0.6661\n",
            "\n",
            "Epoch 9/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 23/23 [00:08<00:00,  2.65it/s]\n",
            "Evaluating: 100%|██████████| 10/10 [00:00<00:00, 14.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0650 | Val PSNR: 16.09, SSIM: 0.6721\n",
            "\n",
            "Epoch 10/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 23/23 [00:07<00:00,  3.01it/s]\n",
            "Evaluating: 100%|██████████| 10/10 [00:00<00:00, 13.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0634 | Val PSNR: 16.25, SSIM: 0.6777\n",
            "\n",
            "Epoch 11/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 23/23 [00:08<00:00,  2.62it/s]\n",
            "Evaluating: 100%|██████████| 10/10 [00:00<00:00, 13.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0610 | Val PSNR: 16.41, SSIM: 0.6824\n",
            "\n",
            "Epoch 12/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 23/23 [00:08<00:00,  2.81it/s]\n",
            "Evaluating: 100%|██████████| 10/10 [00:00<00:00, 10.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0594 | Val PSNR: 16.55, SSIM: 0.6867\n",
            "\n",
            "Epoch 13/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 23/23 [00:07<00:00,  2.89it/s]\n",
            "Evaluating: 100%|██████████| 10/10 [00:00<00:00, 13.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0581 | Val PSNR: 16.68, SSIM: 0.6905\n",
            "\n",
            "Epoch 14/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 23/23 [00:08<00:00,  2.64it/s]\n",
            "Evaluating: 100%|██████████| 10/10 [00:00<00:00, 13.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0567 | Val PSNR: 16.80, SSIM: 0.6938\n",
            "\n",
            "Epoch 15/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 23/23 [00:07<00:00,  3.08it/s]\n",
            "Evaluating: 100%|██████████| 10/10 [00:00<00:00, 10.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0557 | Val PSNR: 16.92, SSIM: 0.6967\n",
            "\n",
            "Epoch 16/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 23/23 [00:08<00:00,  2.73it/s]\n",
            "Evaluating: 100%|██████████| 10/10 [00:00<00:00, 14.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0546 | Val PSNR: 17.02, SSIM: 0.6994\n",
            "\n",
            "Epoch 17/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 23/23 [00:08<00:00,  2.70it/s]\n",
            "Evaluating: 100%|██████████| 10/10 [00:00<00:00, 10.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0541 | Val PSNR: 17.12, SSIM: 0.7017\n",
            "\n",
            "Epoch 18/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 23/23 [00:07<00:00,  3.01it/s]\n",
            "Evaluating: 100%|██████████| 10/10 [00:00<00:00, 14.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0531 | Val PSNR: 17.21, SSIM: 0.7039\n",
            "\n",
            "Epoch 19/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 23/23 [00:08<00:00,  2.61it/s]\n",
            "Evaluating: 100%|██████████| 10/10 [00:00<00:00, 13.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0530 | Val PSNR: 17.30, SSIM: 0.7057\n",
            "\n",
            "Epoch 20/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 23/23 [00:07<00:00,  2.93it/s]\n",
            "Evaluating: 100%|██████████| 10/10 [00:01<00:00,  9.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0516 | Val PSNR: 17.37, SSIM: 0.7075\n",
            "\n",
            "✅ Model saved to /content/retinexmamba_trained.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}